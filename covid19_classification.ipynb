{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIGn8z7JhId8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy \n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip 'Assignment 5 Dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcXFz0q4mwmd"
   },
   "outputs": [],
   "source": [
    "# roll number\n",
    "roll_num = 69\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEnLJnDpiWmK"
   },
   "outputs": [],
   "source": [
    "data_dir = 'Assignment 5 Dataset'\n",
    "\n",
    "# Defining transformations\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70489,
     "status": "ok",
     "timestamp": 1587773086412,
     "user": {
      "displayName": "Hamza Ahmed",
      "photoUrl": "",
      "userId": "09842705533450292659"
     },
     "user_tz": -300
    },
    "id": "FjxK-npUiXob",
    "outputId": "0b9eb07e-3544-48cd-aed3-7d7886cc09c1"
   },
   "outputs": [],
   "source": [
    "# Applying transformations on the data\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(data_dir + '/validation', transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "\n",
    "# Data Loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Classes: \")\n",
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99367,
     "status": "ok",
     "timestamp": 1587773115572,
     "user": {
      "displayName": "Hamza Ahmed",
      "photoUrl": "",
      "userId": "09842705533450292659"
     },
     "user_tz": -300
    },
    "id": "vgu6kEvgnByW",
    "outputId": "5983aa3e-5670-47a6-a3b0-90356b65ab6e"
   },
   "outputs": [],
   "source": [
    "# Showing Images\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148,
     "referenced_widgets": [
      "431af69652084e87bccdec7f27f51d61",
      "d72f7ca3e3cb4924a8d59142ef2cdf67",
      "b506d0f8e99a4f90aaf9131fdeaddfe3",
      "b104d5c3f9d241c18377aa5379ebf911",
      "fbb0accada21422796b322f1bf2b4e1c",
      "a8670935d57b47068ed9533d10c00de7",
      "23dcb0cab6a34e968ae39cce328f73ce",
      "05b61251cd8549aaa95493e596151509",
      "647efcd676364475a785fd1f71100588",
      "f221da11e41a4764a38de7cd75a89e47",
      "d323a7ed5f4d452cb8876d864493aa2f",
      "dbfe9cb0124747f994ecacc3b9db85fb",
      "0b39cfa8efbe4339bb37afe16f5ffc87",
      "86ee7f28c4d44be3b59bfed21f07710a",
      "4b977e4d05f3406fbcbd7193c99da425",
      "eb35cdc46f6541969af8fd5cf3f44714"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 106192,
     "status": "ok",
     "timestamp": 1587773127874,
     "user": {
      "displayName": "Hamza Ahmed",
      "photoUrl": "",
      "userId": "09842705533450292659"
     },
     "user_tz": -300
    },
    "id": "SJ8dTPp0ib3s",
    "outputId": "97c5d9f6-fbc5-4399-dd32-f41ca57afc8a"
   },
   "outputs": [],
   "source": [
    "# Load the pretrained models from pytorch\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# resnet18 = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5F6-Fj1nhG_"
   },
   "outputs": [],
   "source": [
    "# Freeze training for all layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing and Adding New Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 100638,
     "status": "error",
     "timestamp": 1587773127876,
     "user": {
      "displayName": "Hamza Ahmed",
      "photoUrl": "",
      "userId": "09842705533450292659"
     },
     "user_tz": -300
    },
    "id": "ObwCKIKWn0iy",
    "outputId": "d7b758b2-97ff-4baf-ed2a-f0698cb78cfb"
   },
   "outputs": [],
   "source": [
    "# Removing Last Line\n",
    "num_features = vgg16.classifier[0].in_features\n",
    "features = list(vgg16.classifier.children())[0:-7] # Remove last layer\n",
    "\n",
    "# resnet18 = nn.Sequential(*list(resnet18.modules())[:-1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSKtalhQoKKo"
   },
   "outputs": [],
   "source": [
    "new_feature = ( roll_num * 10 ) + 100\n",
    "# Adding Layers\n",
    "# vgg16\n",
    "features.extend([nn.Linear(num_features, new_feature)])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature)])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, len(class_names) )])\n",
    "vgg16.classifier = nn.Sequential(*features)\n",
    "\n",
    "# resNet18\n",
    "resnet18.fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(512, new_feature)), ('relu', nn.ReLU()), ('fc2', nn.Linear(new_feature, 2)), ('output', nn.LogSoftmax(dim=1))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137007,
     "status": "ok",
     "timestamp": 1587765125656,
     "user": {
      "displayName": "Hamza Ahmed",
      "photoUrl": "",
      "userId": "09842705533450292659"
     },
     "user_tz": -300
    },
    "id": "3a92ZzozpqsE",
    "outputId": "1273167a-499a-4d53-aecc-6bb2cae0ab96"
   },
   "outputs": [],
   "source": [
    "# Printing\n",
    "print(vgg16)\n",
    "print('---------------')\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIRaUuaap7Je"
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "vgg16_optimizer = optim.SGD(vgg16.parameters(), lr=0.0001, momentum=0.9)\n",
    "resnet18_optimizer = optim.SGD(resnet18.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10755,
     "status": "ok",
     "timestamp": 1587765136439,
     "user": {
      "displayName": "Hamza Ahmed",
      "photoUrl": "",
      "userId": "09842705533450292659"
     },
     "user_tz": -300
    },
    "id": "5gjYErGIsvet",
    "outputId": "ef04d4af-394d-4d8a-9f2f-90f57486b298"
   },
   "outputs": [],
   "source": [
    "# Setting to either GPU or CPU based on availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZgYNtqkPr3QP",
    "outputId": "0f65098b-aa5d-48bc-af7f-118e0624f473"
   },
   "outputs": [],
   "source": [
    "# Training VGG-16\n",
    "vgg16_cross_entropy = []\n",
    "vgg16_valid_accuracy = []\n",
    "\n",
    "valid_normal_true = 0\n",
    "valid_normal_false = 0\n",
    "valid_infected_true = 0\n",
    "valid_infected_false  = 0\n",
    "\n",
    "\n",
    "# Running Epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        vgg16_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        vgg16_optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    vgg16_cross_entropy.append(loss.data)\n",
    "        \n",
    "    torch.save(vgg16.state_dict(), 'vgg16_FC_Only.pth')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for l, p in zip(labels, predicted):\n",
    "                if(l.item() == 0):\n",
    "                    if(p.item() == 0):\n",
    "                        valid_normal_true +=1\n",
    "                    else:\n",
    "                        valid_normal_false +=1\n",
    "                else:\n",
    "                    if(p.item() == 1):\n",
    "                        valid_infected_true +=1\n",
    "                    else:\n",
    "                        valid_infected_false +=1\n",
    "    vgg16_valid_accuracy.append((100 * correct / total))\n",
    "\n",
    "    \n",
    "print('VGG-16 Trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for VGG-16\n",
    "data = np.array([[valid_normal_true, valid_normal_false],\n",
    "                 [valid_infected_false,valid_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FH_xtn9IuR-K"
   },
   "outputs": [],
   "source": [
    "# Drawing Accuracy of VGG-16\n",
    "print('*** Validation Accuracy ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), vgg16_valid_accuracy, color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print('*** Cross Entropy Curve ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), vgg16_cross_entropy, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8FBIw9k12Rl"
   },
   "outputs": [],
   "source": [
    "# Runing VGG-16 on Test Data\n",
    "test_normal_true = 0\n",
    "test_normal_false = 0\n",
    "test_infected_true = 0\n",
    "test_infected_false = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = vgg16(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for l, p in zip(labels, predicted):\n",
    "            if(l.item() == 0):\n",
    "                if(p.item() == 0):\n",
    "                    test_normal_true +=1\n",
    "                else:\n",
    "                    test_normal_false +=1\n",
    "            else:\n",
    "                if(p.item() == 1):\n",
    "                    test_infected_true +=1\n",
    "                else:\n",
    "                    test_infected_false +=1\n",
    "    print('Accuracy of the test Data : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for VGG-16 Test data\n",
    "data = np.array([[test_normal_true, test_normal_false],\n",
    "                 [test_infected_false,test_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reacall Precision and F_Score for Tesing Data of VGG-16\n",
    "test_recall = 0\n",
    "test_precision = 0 \n",
    "test_f_score = 0\n",
    "\n",
    "test_recall = test_normal_true/(test_normal_true+test_normal_false)\n",
    "test_precision = test_normal_true/(test_normal_true+valid_normal_false)\n",
    "test_f_score = 2*(test_precision*test_recall)/(test_precision+test_recall)\n",
    "print('VGG-16 Valid F1 Score: %d %%' % (100 * test_f_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ot27wT0HtA4p",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training RexNet-18\n",
    "resnet18_cross_entropy = []\n",
    "resnet18_valid_accuracy = []\n",
    "\n",
    "valid_normal_true = 0\n",
    "valid_normal_false = 0\n",
    "valid_infected_true = 0\n",
    "valid_infected_false  = 0\n",
    "\n",
    "\n",
    "# Running Epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        resnet18_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        resnet18_optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    resnet18_cross_entropy.append(loss.data)\n",
    "        \n",
    "    torch.save(resnet18.state_dict(), 'res18_FC_Only.pth')\n",
    "     \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for l, p in zip(labels, predicted):\n",
    "                if(l.item() == 0):\n",
    "                    if(p.item() == 0):\n",
    "                        valid_normal_true +=1\n",
    "                    else:\n",
    "                        valid_normal_false +=1\n",
    "                else:\n",
    "                    if(p.item() == 1):\n",
    "                        valid_infected_true +=1\n",
    "                    else:\n",
    "                        valid_infected_false +=1\n",
    " \n",
    "    resnet18_valid_accuracy.append((100 * correct / total))\n",
    "    \n",
    "\n",
    "print('ResNet-18 Trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for ResNet-18\n",
    "data = np.array([[valid_normal_true, valid_normal_false],\n",
    "                 [valid_infected_false,valid_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4ARvGj31s_9"
   },
   "outputs": [],
   "source": [
    "# Drawing Accuracy of ResNet-18\n",
    "print('*** Validation Accuracy ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), resnet18_valid_accuracy, color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print('*** Cross Entropy Curve ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), resnet18_cross_entropy, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing ResNet-18 on Testing Data\n",
    "test_normal_true = 0\n",
    "test_normal_false = 0\n",
    "test_infected_true = 0\n",
    "test_infected_false = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for l, p in zip(labels, predicted):\n",
    "            if(l.item() == 0):\n",
    "                if(p.item() == 0):\n",
    "                    test_normal_true +=1\n",
    "                else:\n",
    "                    test_normal_false +=1\n",
    "            else:\n",
    "                if(p.item() == 1):\n",
    "                    test_infected_true +=1\n",
    "                else:\n",
    "                    test_infected_false +=1\n",
    "    print('Accuracy of the test Data : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for ResNet-18 Test data\n",
    "data = np.array([[test_normal_true, test_normal_false],\n",
    "                 [test_infected_false,test_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reacall Precision and F_Score for Tesing Data of ResNet-18\n",
    "test_recall = 0\n",
    "test_precision = 0 \n",
    "test_f_score = 0\n",
    "\n",
    "test_recall = test_normal_true/(test_normal_true+test_normal_false)\n",
    "test_precision = test_normal_true/(test_normal_true+valid_normal_false)\n",
    "test_f_score = 2*(test_precision*test_recall)/(test_precision+test_recall)\n",
    "print('ResNet test F1 Score: %d %%' % (100 * test_f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing Few Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialzing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJFfENEq_ho3"
   },
   "outputs": [],
   "source": [
    "# Initialize Network\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkIf9xJx_oqY"
   },
   "outputs": [],
   "source": [
    "# Feezing only even layers\n",
    "\n",
    "# count = 0\n",
    "# for param in vgg16.features:\n",
    "#     print(count,param)\n",
    "#     count +=1\n",
    "    \n",
    "count = 0\n",
    "\n",
    "for param in vgg16.features.parameters():\n",
    "    if count == 0 or count == 2 or count == 5 or count == 10 or count == 14 or count ==21 or count == 26:\n",
    "        param.require_grad = False\n",
    "    count += 1\n",
    "count = 0\n",
    "\n",
    "for param in resnet18.parameters():\n",
    "    if count%4 == 0:\n",
    "        param.require_grad = False\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing and Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReqMKKQU_zXU"
   },
   "outputs": [],
   "source": [
    "# Removing Last Line\n",
    "\n",
    "num_features = vgg16.classifier[0].in_features\n",
    "features = list(vgg16.classifier.children())[:-7] # Remove last layer\n",
    "\n",
    "# resnet18 = nn.Sequential(*list(resnet18.modules())[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcn_ChJG_2eh"
   },
   "outputs": [],
   "source": [
    "new_feature = ( roll_num * 10 ) + 100\n",
    "# Adding Layers\n",
    "\n",
    "features.extend([nn.Linear(num_features, new_feature)])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature)])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, len(class_names) )])\n",
    "vgg16.classifier = nn.Sequential(*features)\n",
    "\n",
    "# resNet18\n",
    "resnet18.fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(512, new_feature)), ('relu', nn.ReLU()), ('fc2', nn.Linear(new_feature, 2)), ('output', nn.LogSoftmax(dim=1))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7J7Ldb6_6u6"
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "vgg16_optimizer = optim.SGD(vgg16.parameters(), lr=0.0001, momentum=0.9)\n",
    "resnet18_optimizer = optim.SGD(resnet18.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X82OQFIH_96F"
   },
   "outputs": [],
   "source": [
    "# Setting to either GPU or CPU based on availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riyJPvCuABw8"
   },
   "outputs": [],
   "source": [
    "# training VGG-16\n",
    "vgg16_cross_entropy = []\n",
    "vgg16_valid_accuracy = []\n",
    "\n",
    "valid_normal_true = 0\n",
    "valid_normal_false = 0\n",
    "valid_infected_true = 0\n",
    "valid_infected_false  = 0\n",
    "\n",
    "\n",
    "\n",
    "# Running Epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        vgg16_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        vgg16_optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    vgg16_cross_entropy.append(loss.data)\n",
    "        \n",
    "#     torch.save(vgg16.state_dict(), 'vgg16_FC_Only.pth')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for l, p in zip(labels, predicted):\n",
    "                if(l.item() == 0):\n",
    "                    if(p.item() == 0):\n",
    "                        valid_normal_true +=1\n",
    "                    else:\n",
    "                        valid_normal_false +=1\n",
    "                else:\n",
    "                    if(p.item() == 1):\n",
    "                        valid_infected_true +=1\n",
    "                    else:\n",
    "                        valid_infected_false +=1\n",
    "    vgg16_valid_accuracy.append((100 * correct / total))\n",
    "\n",
    "print('VGG-16 Trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing Confusion Table for VGG-16 Some Layers Freeze\n",
    "data = np.array([[valid_normal_true, valid_normal_false],\n",
    "                 [valid_infected_false,valid_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Accuracy of VGG-16 Some Layers Freeze\n",
    "print('*** Validation Accuracy ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), vgg16_valid_accuracy, color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print('*** Cross Entropy Curve ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), vgg16_cross_entropy, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing VGG-16 on Testing Data\n",
    "test_normal_true = 0\n",
    "test_normal_false = 0\n",
    "test_infected_true = 0\n",
    "test_infected_false = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = vgg16(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for l, p in zip(labels, predicted):\n",
    "            if(l.item() == 0):\n",
    "                if(p.item() == 0):\n",
    "                    test_normal_true +=1\n",
    "                else:\n",
    "                    test_normal_false +=1\n",
    "            else:\n",
    "                if(p.item() == 1):\n",
    "                    test_infected_true +=1\n",
    "                else:\n",
    "                    test_infected_false +=1\n",
    "    print('Accuracy of VGG-16 model on the test Data : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for VGG-16 \n",
    "data = np.array([[test_normal_true, test_normal_false],\n",
    "                 [test_infected_false, test_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reacall Precision and F_Score for Tesing Data of VGG-16\n",
    "test_recall = 0\n",
    "test_precision = 0 \n",
    "test_f_score = 0\n",
    "\n",
    "test_recall = test_normal_true/(test_normal_true+test_normal_false)\n",
    "test_precision = test_normal_true/(test_normal_true+valid_normal_false)\n",
    "test_f_score = 2*(test_precision*test_recall)/(test_precision+test_recall)\n",
    "print('VGG-16 Valid F1 Score: %d %%' % (100 * test_f_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9gqWlBjAEKY"
   },
   "outputs": [],
   "source": [
    "# Training ResNet-18\n",
    "resnet18_cross_entropy = []\n",
    "resnet18_valid_accuracy = []\n",
    "resnet18_train_accuracy = []\n",
    "valid_normal_true = 0\n",
    "valid_normal_false = 0\n",
    "valid_infected_true = 0\n",
    "valid_infected_false  = 0\n",
    "\n",
    "# Running Epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        resnet18_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        resnet18_optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    resnet18_cross_entropy.append(loss.data)\n",
    "        \n",
    "#     torch.save(resnet18.state_dict(), 'res18_FC_Only.pth')\n",
    "     \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for l, p in zip(labels, predicted):\n",
    "                if(l.item() == 0):\n",
    "                    if(p.item() == 0):\n",
    "                        valid_normal_true +=1\n",
    "                    else:\n",
    "                        valid_normal_false +=1\n",
    "                else:\n",
    "                    if(p.item() == 1):\n",
    "                        valid_infected_true +=1\n",
    "                    else:\n",
    "                        valid_infected_false +=1\n",
    "    resnet18_train_accuracy.append((100 * correct / total))\n",
    "\n",
    "    \n",
    "    \n",
    "print('ResNet-18 Trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN017InxAJfV"
   },
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for ResNet-18\n",
    "data = np.array([[valid_normal_true, valid_normal_false],\n",
    "                 [valid_infected_false,valid_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Accuracy of ResNet-18\n",
    "print('*** Validation Accuracy ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), resnet18_train_accuracy, color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print('*** Cross Entropy Curve ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), resnet18_cross_entropy, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing ResNet-18 on Testing Data\n",
    "test_normal_true = 0\n",
    "test_normal_false = 0\n",
    "test_infected_true = 0\n",
    "test_infected_false = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for l, p in zip(labels, predicted):\n",
    "            if(l.item() == 0):\n",
    "                if(p.item() == 0):\n",
    "                    test_normal_true +=1\n",
    "                else:\n",
    "                    test_normal_false +=1\n",
    "            else:\n",
    "                if(p.item() == 1):\n",
    "                    test_infected_true +=1\n",
    "                else:\n",
    "                    test_infected_false +=1\n",
    "    print('Accuracy of ResNet Model on the test Data : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reacall Precision and F_Score for Tesing Data of ResNet-18\n",
    "test_recall = 0\n",
    "test_precision = 0 \n",
    "test_f_score = 0\n",
    "\n",
    "test_recall = test_normal_true/(test_normal_true+test_normal_false)\n",
    "test_precision = test_normal_true/(test_normal_true+valid_normal_false)\n",
    "test_f_score = 2*(test_precision*test_recall)/(test_precision+test_recall)\n",
    "print('ResNet-18 Valid F1 Score: %d %%' % (100 * test_f_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnFreezing All Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Network\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and Removing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Last Line\n",
    "\n",
    "num_features = vgg16.classifier[0].in_features\n",
    "features = list(vgg16.classifier.children())[0:-7] # Remove last layer\n",
    "\n",
    "# resnet18 = nn.Sequential(*list(resnet18.modules())[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = ( roll_num * 10 ) + 100\n",
    "# Adding Layers\n",
    "# vgg16\n",
    "features.extend([nn.Linear(num_features, new_feature)])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature )])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, new_feature)])\n",
    "features.extend([nn.ReLU(inplace=True)])\n",
    "features.extend([nn.Dropout(p=0.5, inplace=False)])\n",
    "features.extend([nn.Linear( new_feature, len(class_names) )])\n",
    "vgg16.classifier = nn.Sequential(*features)\n",
    "\n",
    "# resNet18\n",
    "resnet18.fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(512, new_feature)), ('relu', nn.ReLU()), ('fc2', nn.Linear(new_feature, 2)), ('output', nn.LogSoftmax(dim=1))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "vgg16_optimizer = optim.SGD(vgg16.parameters(), lr=0.0001, momentum=0.9)\n",
    "resnet18_optimizer = optim.SGD(resnet18.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting to either GPU or CPU based on availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16.to(device)\n",
    "\n",
    "vgg16.train()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "\n",
    "resnet18.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training VGG-16\n",
    "vgg16_cross_entropy = []\n",
    "vgg16_valid_accuracy = []\n",
    "\n",
    "valid_normal_true = 0\n",
    "valid_normal_false = 0\n",
    "valid_infected_true = 0\n",
    "valid_infected_false  = 0\n",
    "\n",
    "# Running Epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        vgg16_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = vgg16(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        vgg16_optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    vgg16_cross_entropy.append(loss.data)\n",
    "        \n",
    "    torch.save(vgg16.state_dict(), 'vgg16_FC_Entire.pth')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for l, p in zip(labels, predicted):\n",
    "                if(l.item() == 0):\n",
    "                    if(p.item() == 0):\n",
    "                        valid_normal_true +=1\n",
    "                    else:\n",
    "                        valid_normal_false +=1\n",
    "                else:\n",
    "                    if(p.item() == 1):\n",
    "                        valid_infected_true +=1\n",
    "                    else:\n",
    "                        valid_infected_false +=1\n",
    "    vgg16_valid_accuracy.append((100 * correct / total))\n",
    "\n",
    "    \n",
    "print('VGG-16 Trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for VGG-16\n",
    "data = np.array([[valid_normal_true, valid_normal_false],\n",
    "                 [valid_infected_false,valid_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Accuracy of VGG-16\n",
    "print('*** Validation Accuracy ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), vgg16_valid_accuracy, color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print('*** Cross Entropy Curve ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), vgg16_cross_entropy, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing VGG-18 on Testing Data\n",
    "test_normal_true = 0\n",
    "test_normal_false = 0\n",
    "test_infected_true = 0\n",
    "test_infected_false = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = vgg16(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for l, p in zip(labels, predicted):\n",
    "            if(l.item() == 0):\n",
    "                if(p.item() == 0):\n",
    "                    test_normal_true +=1\n",
    "                else:\n",
    "                    test_normal_false +=1\n",
    "            else:\n",
    "                if(p.item() == 1):\n",
    "                    test_infected_true +=1\n",
    "                else:\n",
    "                    test_infected_false +=1\n",
    "                    \n",
    "    print('Accuracy of VGG-16 Model on the test Data : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing Confusion Table for VGG Test data\n",
    "data = np.array([[test_normal_true, test_normal_false],\n",
    "                 [test_infected_false,test_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "precision = test_normal_true/(test_normal_true+test_normal_false)\n",
    "recall = test_normal_true/(test_normal_true+test_infected_false)\n",
    "f_score = 2*(precision*recall)/(precision+recall)\n",
    "print('VGG Test F1 Score: %d %%' % (100 * f_score))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing ResNet-18\n",
    "resnet18_cross_entropy = []\n",
    "resnet18_valid_accuracy = []\n",
    "\n",
    "valid_normal_true = 0\n",
    "valid_normal_false = 0\n",
    "valid_infected_true = 0\n",
    "valid_infected_false  = 0\n",
    "\n",
    "# Running Epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for i, data in pbar:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        resnet18_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet18(inputs)               #----> forward pass\n",
    "        loss = criterion(outputs, labels)   #----> compute loss\n",
    "        loss.backward()                     #----> backward pass\n",
    "        resnet18_optimizer.step()                    #----> weights update\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader),\n",
    "                loss.data))\n",
    "        \n",
    "    resnet18_cross_entropy.append(loss.data)\n",
    "        \n",
    "    torch.save(resnet18.state_dict(), 'res18_FC_Only.pth')\n",
    "     \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for l, p in zip(labels, predicted):\n",
    "                if(l.item() == 0):\n",
    "                    if(p.item() == 0):\n",
    "                        valid_normal_true +=1\n",
    "                    else:\n",
    "                        valid_normal_false +=1\n",
    "                else:\n",
    "                    if(p.item() == 1):\n",
    "                        valid_infected_true +=1\n",
    "                    else:\n",
    "                        valid_infected_false +=1\n",
    "    resnet18_valid_accuracy.append((100 * correct / total))\n",
    "\n",
    "    \n",
    "print('ResNet-18 Trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for ResNet-18\n",
    "data = np.array([[valid_normal_true, valid_normal_false],\n",
    "                 [valid_infected_false,valid_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Accuracy of ResNet-18\n",
    "print('*** Validation Accuracy ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), resnet18_valid_accuracy, color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print('*** Cross Entropy Curve ***')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(epochs), resnet18_cross_entropy, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing ResNet-18 on Testing Data\n",
    "test_normal_true = 0\n",
    "test_normal_false = 0\n",
    "test_infected_true = 0\n",
    "test_infected_false = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for l, p in zip(labels, predicted):\n",
    "            if(l.item() == 0):\n",
    "                if(p.item() == 0):\n",
    "                    test_normal_true +=1\n",
    "                else:\n",
    "                    test_normal_false +=1\n",
    "            else:\n",
    "                if(p.item() == 1):\n",
    "                    test_infected_true +=1\n",
    "                else:\n",
    "                    test_infected_false +=1\n",
    "    print('Accuracy of ResNet Model on the test Data : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "precision = test_normal_true/(test_normal_true+test_normal_false)\n",
    "recall = test_normal_true/(test_normal_true+test_infected_false)\n",
    "f_score = 2*(precision*recall)/(precision+recall)\n",
    "print('ResNet Test F1 Score: %d %%' % (100 * f_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing Confusion Table for ResNet Test data\n",
    "data = np.array([[test_normal_true, test_normal_false],\n",
    "                 [test_infected_false,test_infected_true, ]])\n",
    "print(\"                Predicted Normal      Pridicted False \")\n",
    "\n",
    "row_format =\"{:>15}\" * (len(class_names) + 1)\n",
    "print(row_format.format(\"\", *class_names))\n",
    "for team, row in zip(class_names, data):\n",
    "    print( row_format.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMGIXDMLngme0dbmWiqVjlr",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1hpKvB69hQRdvQ09xc_3SPFvcZuJ-5uqS",
   "name": "MSDS19069_05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05b61251cd8549aaa95493e596151509": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b39cfa8efbe4339bb37afe16f5ffc87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "23dcb0cab6a34e968ae39cce328f73ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "431af69652084e87bccdec7f27f51d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b506d0f8e99a4f90aaf9131fdeaddfe3",
       "IPY_MODEL_b104d5c3f9d241c18377aa5379ebf911"
      ],
      "layout": "IPY_MODEL_d72f7ca3e3cb4924a8d59142ef2cdf67"
     }
    },
    "4b977e4d05f3406fbcbd7193c99da425": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "647efcd676364475a785fd1f71100588": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d323a7ed5f4d452cb8876d864493aa2f",
       "IPY_MODEL_dbfe9cb0124747f994ecacc3b9db85fb"
      ],
      "layout": "IPY_MODEL_f221da11e41a4764a38de7cd75a89e47"
     }
    },
    "86ee7f28c4d44be3b59bfed21f07710a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8670935d57b47068ed9533d10c00de7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b104d5c3f9d241c18377aa5379ebf911": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05b61251cd8549aaa95493e596151509",
      "placeholder": "",
      "style": "IPY_MODEL_23dcb0cab6a34e968ae39cce328f73ce",
      "value": " 528M/528M [00:09&lt;00:00, 58.3MB/s]"
     }
    },
    "b506d0f8e99a4f90aaf9131fdeaddfe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8670935d57b47068ed9533d10c00de7",
      "max": 553433881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbb0accada21422796b322f1bf2b4e1c",
      "value": 553433881
     }
    },
    "d323a7ed5f4d452cb8876d864493aa2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86ee7f28c4d44be3b59bfed21f07710a",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b39cfa8efbe4339bb37afe16f5ffc87",
      "value": 46827520
     }
    },
    "d72f7ca3e3cb4924a8d59142ef2cdf67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbfe9cb0124747f994ecacc3b9db85fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb35cdc46f6541969af8fd5cf3f44714",
      "placeholder": "",
      "style": "IPY_MODEL_4b977e4d05f3406fbcbd7193c99da425",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 61.0MB/s]"
     }
    },
    "eb35cdc46f6541969af8fd5cf3f44714": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f221da11e41a4764a38de7cd75a89e47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbb0accada21422796b322f1bf2b4e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
